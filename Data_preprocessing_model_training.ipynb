{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Model Training\n",
    "This notebook performs data preprocessing and trains a Random Forest classifier on the Titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "We import necessary libraries for data manipulation, visualization, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset\n",
    "Load the Titanic dataset from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset=pd.read_csv('tested.csv')\n",
    "Dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Shuffle Split\n",
    "We split the dataset into training and testing sets using stratified sampling based on 'Survived', 'Pclass', and 'Sex' to maintain the distribution of these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1,test_size=0.2)\n",
    "\n",
    "for train_indices,test_indices in split.split(Dataset,Dataset[['Survived','Pclass','Sex']]):\n",
    "    Train_set=Dataset.loc[train_indices]\n",
    "    Test_set=Dataset.loc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Split\n",
    "Plot histograms of 'Survived' and 'Pclass' for both training and testing sets to verify the stratified split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40569b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "Train_set['Survived'].hist()\n",
    "Train_set['Pclass'].hist()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "Test_set['Survived'].hist()\n",
    "Test_set['Pclass'].hist()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed6672f",
   "metadata": {},
   "source": [
    "## Custom Transformer: Age Imputer\n",
    "Define a transformer to impute missing values in the 'Age' column using the mean strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e3d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "class AgeImputer(BaseEstimator,TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        imputer=SimpleImputer(strategy=\"mean\")\n",
    "        X['Age']=imputer.fit_transform(X[['Age']])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ca2b63",
   "metadata": {},
   "source": [
    "## Custom Transformer: Feature Encoder\n",
    "Encode categorical features 'Embarked' and 'Sex' using one-hot encoding and add them as new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e12647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class FeatureEncoder(BaseEstimator,TransformerMixin):\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        encoder=OneHotEncoder()\n",
    "        matrix=encoder.fit_transform(X[['Embarked']]).toarray()\n",
    "        column_names=[\"C\",\"S\",\"Q\",\"N\"]\n",
    "        for i in range(len(matrix.T)):\n",
    "            X[column_names[i]]=matrix.T[i]\n",
    "        matrix=encoder.fit_transform(X[['Sex']]).toarray()\n",
    "        column_names=[\"Female\",\"Male\"]\n",
    "        for i in range(len(matrix.T)):\n",
    "            X[column_names[i]]=matrix.T[i]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ca1926",
   "metadata": {},
   "source": [
    "## Custom Transformer: Feature Dropper\n",
    "Drop unnecessary columns that are not used for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56497ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureDropper(BaseEstimator,TransformerMixin):\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X.drop([\"Embarked\",\"Name\",\"Ticket\",\"Cabin\",\"Sex\",\"N\"],axis=1,errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69199529",
   "metadata": {},
   "source": [
    "## Pipeline Creation\n",
    "Create a pipeline to apply the custom transformers sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([(\"ageimputer\",AgeImputer()),\n",
    "                    (\"featureencoder\",FeatureEncoder()),\n",
    "                    (\"featuredropper\",FeatureDropper())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f2f054",
   "metadata": {},
   "source": [
    "## Transform Training Set\n",
    "Apply the pipeline transformations to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95dc437",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_set=pipeline.fit_transform(Train_set)\n",
    "Train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337b6539",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "Scale the features using StandardScaler for better model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c796e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X=Train_set.drop(['Survived'],axis=1)\n",
    "y=Train_set['Survived']\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_data=scaler.fit_transform(X)\n",
    "y_data=y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a560f496",
   "metadata": {},
   "source": [
    "## Model Training with Random Forest and Grid Search\n",
    "Train a Random Forest classifier and tune hyperparameters using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf=RandomForestClassifier()\n",
    "\n",
    "param_grid=[\n",
    "    {\"n_estimators\":[10,100,200,500],\"max_depth\":[None,5,10],\"min_samples_split\":[2,3,4]}\n",
    "]\n",
    "\n",
    "grid_search=GridSearchCV(clf, param_grid, cv=3, scoring=\"accuracy\", return_train_score=True)\n",
    "grid_search.fit(X_data,y_data)\n",
    "final_clf=grid_search.best_estimator_\n",
    "final_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2604faa3",
   "metadata": {},
   "source": [
    "## Transform Test Set\n",
    "Apply the same pipeline and scaling to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf037b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set=pipeline.fit_transform(Test_set)\n",
    "X_test=Test_set.drop(['Survived'],axis=1)\n",
    "y_test=Test_set['Survived']\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X_data_test=scaler.fit_transform(X_test)\n",
    "y_data_test=y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7671d5b6",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluate the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a010b2d2",
   "metadata": [],
   "outputs": [],
   "source": [
    "final_clf.score(X_data_test,y_data_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
